#include <opencv2/opencv.hpp>
#include <map>
#include <chrono>
#include <thread>

#include "common/engine_loader.h"
#include "common/framework.h"
#include "yolo/yolov8_utils.h"


int main() {
    // 使用智能指针加载 TensorRT 引擎
    auto engine = loadEngineFromFile("./models/yolov8n-pose.common");
    if (!engine) {
        std::cerr << "Failed to load common." << std::endl;
        return -1;
    }

    // 使用智能指针创建执行上下文
    auto context = createExecutionContext(engine.get());

    // 获取与模型有关的 Tensors
    auto gpu_tensors = loadTensorsFromModel(engine.get());

    // バッファを初期化
    initCudaTemporaryBuffer(640, 640);

    //　結果を保存するための変数
    std::vector<YoloPoseResult> results;

    // ビデオのパス
    std::string video_path = "videos/family_01.mp4";

    // FPSを計算
    int frame_count = 0;
    double fps = 0.0;
    auto start_time = std::chrono::high_resolution_clock::now();

    bool run_inference = true;
    while (run_inference) {
        // ビデオを読み込む
        cv::VideoCapture cap(video_path);
        if (!cap.isOpened()) {
            std::cerr << "Failed to open video file." << std::endl;
            return -1;
        }

        cv::Mat frame;
        cv::Mat resized_frame;

        while (cap.read(frame)) {
            // フレームをリサイズ
            cv::resize(frame, resized_frame, cv::Size(640, 640));

            // 画像を前処理
            preprocess(resized_frame, gpu_tensors["images"]);

            // 推論を実行
            inference(context,
                      gpu_tensors["images"].ptr(),
                      gpu_tensors["output0"].ptr());

            // 後処理
            postprocess(gpu_tensors["output0"], 0.3, results);

            // Display detection results
            for (const auto& result : results) {
                cv::rectangle(resized_frame, cv::Point(result.lx, result.ly), cv::Point(result.rx, result.ry), cv::Scalar(0, 255, 0), 2);
            }

            // FPS計算のためのフレーム数をカウント
            frame_count++;

            // 1秒経過した場合、FPSを計算して表示
            auto end_time = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double> elapsed_time = end_time - start_time;
            if (elapsed_time.count() >= 1.0) {
                fps = frame_count / elapsed_time.count();
                frame_count = 0;
                start_time = end_time;
            }

            // フレームにFPSを描画
            std::string fps_text = "FPS: " + std::to_string(fps);
            cv::putText(resized_frame, fps_text, cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 1.0, cv::Scalar(0, 255, 0), 2);

            // Display video frame
            cv::imshow("Video", resized_frame);
            if (cv::waitKey(1) == 27) {
                run_inference = false;
                break;
            }
        }

        // Track memory usage (for detecting memory leaks or overflow)
        trackMemoryUsage();

        // Release video and reset the capture to loop the video
        cap.release();

        std::cout << "Video loop ended, restarting video..." << std::endl;

        // Optional: sleep to prevent too tight of a loop (you can adjust the delay if needed)
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }

    // Release other resources
    releaseCudaTemporaryBuffer();

    // ウィンドウを閉じる
    cv::destroyAllWindows();

    return 0;
}
